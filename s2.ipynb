{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vo={\n",
    "    'a':'',\n",
    "    'aa':'ा',\n",
    "    'i':'ि',\n",
    "    'ee':'ी',\n",
    "    'u':'ु',\n",
    "    'oo':'ू',\n",
    "    'e':'े',\n",
    "    'ai':'ै',\n",
    "    'o':'ो',\n",
    "    'au':'ौ'\n",
    "}\n",
    "\n",
    "voa={\n",
    "    'a':'अ',\n",
    "    'aa':'आ',\n",
    "    'i':'इ',\n",
    "    'ee':'ई',\n",
    "    'u':'उ',\n",
    "    'oo':'ऊ',\n",
    "    'e':'ए',\n",
    "    'ai':'ऐ',\n",
    "    'o':'ओ',\n",
    "    'au':'औ'\n",
    "}\n",
    "\n",
    "\n",
    "co1 ={\n",
    "    'c':'क',\n",
    "    'q':'क',\n",
    "    'k':'क',\n",
    "    'g':'ग',\n",
    "    'x':'छ',\n",
    "    'j':'ज',\n",
    "    'z':'ज',\n",
    "    'p':'प',\n",
    "    'f':'फ',\n",
    "    'v':'भ',\n",
    "    'm':'म',\n",
    "    'y':'य',\n",
    "    'r':'र',\n",
    "    'l':'ल',\n",
    "    'w':'व',\n",
    "    'h':'ह',\n",
    "    \n",
    "}\n",
    "\n",
    "co2 = {\n",
    "    'kh':'ख',\n",
    "    'gh':'घ',\n",
    "    'ch':'च',\n",
    "    'jh':'झ',\n",
    "    'ph':'फ',\n",
    "    'bh':'भ',\n",
    "    'sh':'श',\n",
    "    'jn':'ज्ञ'\n",
    "}\n",
    "\n",
    "co3={\n",
    "    'chh':'छ',\n",
    "    'ksh':'क्ष',\n",
    "    'gny':'ज्ञ'\n",
    "}\n",
    "\n",
    "coar={\n",
    "    'b':['ब','व'],\n",
    "    's':['स','श','ष'],\n",
    "    't':['ट','त'],\n",
    "    'th':['ठ','थ'],\n",
    "    'd':['ड','द'],\n",
    "    'dh':['ढ','ध'],\n",
    "    'n':['न','ङ','ञ','ण']\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def suggest(inp):\n",
    "    #inp is english word\n",
    "    inp=inp.lower()\n",
    "    result=\"\"\n",
    "    first=0\n",
    "    resultar=[]\n",
    "    while True:\n",
    "        chunk3 = inp[:3] if len(inp)>2 else ''\n",
    "        chunk2= inp[:2] if len(inp)>1 else ''\n",
    "        chunk1=inp[:1]\n",
    "        if not chunk1: break\n",
    "        is_vowel=False\n",
    "        if chunk3 in co3:\n",
    "            result+=co3[chunk3]\n",
    "            size=3\n",
    "            \n",
    "        elif chunk2 in co2:\n",
    "            result+=co2[chunk2]\n",
    "            size=2\n",
    "        elif chunk1 in co1:\n",
    "            result+=co1[chunk1]\n",
    "            size=1\n",
    "        \n",
    "        elif chunk2 in coar:\n",
    "            aray=coar[chunk2]\n",
    "            tempar=[]\n",
    "            newindex=len(result)\n",
    "            if resultar:\n",
    "                for i in resultar:\n",
    "                    for j in aray:\n",
    "                        tempar.append(i+result[index:newindex]+j)\n",
    "                resultar=tempar[:]\n",
    "            else:\n",
    "                resultar=[result+i for i in aray]\n",
    "            index=len(resultar[0])\n",
    "            result=resultar[0]\n",
    "            size=2\n",
    "        \n",
    "        elif chunk1 in coar:\n",
    "            aray=coar[chunk1]\n",
    "            tempar=[]\n",
    "            newindex=len(result)\n",
    "            if resultar:\n",
    "                for i in resultar:\n",
    "                    for j in aray:\n",
    "                        tempar.append(i+result[index:newindex]+j)\n",
    "                resultar=tempar[:]\n",
    "            elif chunk1=='n' and not result:\n",
    "                first=1\n",
    "            else:\n",
    "                resultar=[result+i for i in aray]\n",
    "            \n",
    "            if first:\n",
    "                result='न'\n",
    "                first=0\n",
    "            else:\n",
    "                index=len(resultar[0])\n",
    "                result=resultar[0]\n",
    "            size=1\n",
    "        \n",
    "        elif chunk2 in voa:\n",
    "            is_vowel=True\n",
    "            result+=voa[chunk2]\n",
    "            size=2\n",
    "         \n",
    "        elif chunk1 in voa:\n",
    "            is_vowel=True\n",
    "            result+=voa[chunk1]\n",
    "            size=1\n",
    "           \n",
    "        else:\n",
    "            print(\"X\")\n",
    "            size=len(inp)\n",
    "\n",
    "        inp=inp[size:]\n",
    "        chunk2= inp[:2] if len(inp)>1 else ''\n",
    "        chunk1=inp[:1]\n",
    "        size=0\n",
    "        if not chunk1: break\n",
    "\n",
    "        if chunk2 in vo:\n",
    "            result+=vo[chunk2]\n",
    "            size = 2\n",
    "            \n",
    "        elif chunk1 in vo:\n",
    "            result+=vo[chunk1]\n",
    "            size = 1\n",
    "            pass\n",
    "        else:\n",
    "            if is_vowel:\n",
    "                pass\n",
    "            else:\n",
    "                result+='्'\n",
    "        inp=inp[size:]\n",
    "    \n",
    "    newindex=len(result)\n",
    "    if resultar and index!=newindex:\n",
    "        for i in range(len(resultar)):\n",
    "            resultar[i]+=result[index:newindex]\n",
    "    return result,resultar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('सा', ['सा', 'शा', 'षा'])\n"
     ]
    }
   ],
   "source": [
    "text=\"saa\"\n",
    "print(suggest(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('कन्चनपुर', ['कन्चनपुर', 'कन्चङपुर', 'कन्चञपुर', 'कन्चणपुर', 'कङ्चनपुर', 'कङ्चङपुर', 'कङ्चञपुर', 'कङ्चणपुर', 'कञ्चनपुर', 'कञ्चङपुर', 'कञ्चञपुर', 'कञ्चणपुर', 'कण्चनपुर', 'कण्चङपुर', 'कण्चञपुर', 'कण्चणपुर']) कञ्चनपुर\n"
     ]
    }
   ],
   "source": [
    "r=suggest(\"kanchanapur\")\n",
    "print(r, r[1][8])\n",
    "user_defined={'kanchanpur':'कञ्चनपुर'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('हिन्डी', ['हिन्डी', 'हिन्दी', 'हिङ्डी', 'हिङ्दी', 'हिञ्डी', 'हिञ्दी', 'हिण्डी', 'हिण्दी'])\n"
     ]
    }
   ],
   "source": [
    "print(suggest(\"hindee\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('आराम', [])\n"
     ]
    }
   ],
   "source": [
    "print(suggest(\"aaraam\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('नासा', ['नासा', 'नाशा', 'नाषा'])\n"
     ]
    }
   ],
   "source": [
    "print(suggest(\"naasaa\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map.json is dictionary containing english to nepali words created in new.ipynp \n",
    "with open('map.json') as mp:\n",
    "    mapping = json.load(mp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "d={\n",
    "    'aa':'a',\n",
    "    'z':'j',\n",
    "    'sh':'s',\n",
    "    'f':'ph',\n",
    "    'v':'bh',\n",
    "    'ee':'i',\n",
    "    'oo':'u',\n",
    "    'w':'b'\n",
    "}\n",
    "def funconvert(s):\n",
    "    v=[(m.start(0), m.end(0)) for m in re.finditer('(aa)|z|w|sh|f|v|(oo)|(ee)', s)]\n",
    "    if not v: return s\n",
    "    l=s[:]\n",
    "    for j in v:\n",
    "        key=s[j[0]:j[1]]\n",
    "        l=l.replace(key,d[key],1)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newfun(text):\n",
    "    #prints equivalent nepali unicode text \n",
    "    # 1--by hardcoded rules above\n",
    "    # 2-- by mapping from the generated dictionary map.json\n",
    "    for i in text.split():\n",
    "        print(suggest(i),end=\"\\t\")\n",
    "#         map aa -> a,    f->ph\n",
    "        h=funconvert(i)\n",
    "        print(mapping.get(h,'None'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('मलाइ', [])\t[['मलाइ', 0], ['मलाई', 0]]\n",
      "('रटि', ['रटि', 'रति'])\t[['रति', 0], ['रती', 0], ['राति', 0], ['राती', 0]]\n",
      "('भोक', [])\t[['भोक', 0]]\n",
      "('य्टि', ['य्टि', 'य्ति'])\tNone\n"
     ]
    }
   ],
   "source": [
    "newfun(\"malaai rati vok yti\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('भारट', ['भारट', 'भारत'])\t[['भरत', 0], ['भारत', 0]]\n",
      "('हिन्डि', ['हिन्डि', 'हिन्दि', 'हिङ्डि', 'हिङ्दि', 'हिञ्डि', 'हिञ्दि', 'हिण्डि', 'हिण्दि'])\t[['हिन्दी', 0]]\n",
      "('नेपलि', [])\t[['नेपाली', 0]]\n"
     ]
    }
   ],
   "source": [
    "newfun(\"vaarat hindi nepali\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('नेपलमा', [])\tNone\n"
     ]
    }
   ],
   "source": [
    "newfun(\"nepalamaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('सन्स्कर', ['सन्स्कर', 'सन्श्कर', 'सन्ष्कर', 'सङ्स्कर', 'सङ्श्कर', 'सङ्ष्कर', 'सञ्स्कर', 'सञ्श्कर', 'सञ्ष्कर', 'सण्स्कर', 'सण्श्कर', 'सण्ष्कर', 'शन्स्कर', 'शन्श्कर', 'शन्ष्कर', 'शङ्स्कर', 'शङ्श्कर', 'शङ्ष्कर', 'शञ्स्कर', 'शञ्श्कर', 'शञ्ष्कर', 'शण्स्कर', 'शण्श्कर', 'शण्ष्कर', 'षन्स्कर', 'षन्श्कर', 'षन्ष्कर', 'षङ्स्कर', 'षङ्श्कर', 'षङ्ष्कर', 'षञ्स्कर', 'षञ्श्कर', 'षञ्ष्कर', 'षण्स्कर', 'षण्श्कर', 'षण्ष्कर'])\t[['संस्कार', 0]]\n"
     ]
    }
   ],
   "source": [
    "newfun(\"sanskar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Core Tasks:\n",
    "    Manually add new words to dictionary\n",
    "    Bivakti use garera convert garne: eg.. नेपाल ko conversin hunxa TODO is नेपालकाे 'को' \n",
    "    Corpus banaune sites bata ONlinekhbar\n",
    "    Ngram model train garaune --> \n",
    "        corpus line\n",
    "        ngram banaune dictionary with their frequency\n",
    "            1 gram dictionary = {'मेराे':50, 'म':53, ....}\n",
    "            2 gram dict = {'मेराे देश': 15, 'मेराे नाम':20, .....}\n",
    "            3 gram dict = {'मेराे देश नेपाल': 5, 'मेराे नाम राम्रो':3, .....}\n",
    "            \n",
    "        filter these with threshhold frequency.--> threshold napugeko lai hataune\n",
    "        eg. threshhold = 3\n",
    "        -> gives most frequent 20 thousand grams per each dict created above.\n",
    "        probability nikalne P(देश|मेराे)=(frequency of  मेराे देश)/(freq of मेराे)\n",
    "        \n",
    "UI:\n",
    "    Keyboard ma type garna suru garne bittikai UI on-top appear hunuparyo\n",
    "    Priority based:\n",
    "        1. Suggestions from ngram dictionary\n",
    "        2. Conversion from map.json from s1.ipynb\n",
    "        3. Conversion from statically typed rules in file s2.ipynb\n",
    "    Suggested 3 buttons bata euta click garda or Space handa tyo word insert hunuparne\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input text, d\n",
    "return new dictionary if text is not in d:\n",
    "d = {'a':'23', 'b':'45'}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
